[additional_network_arguments]
unet_lr            = 3e-4
text_encoder_lr    = 2e-5
network_dim        = 32
network_alpha      = 64
network_module     = "lycoris.kohya"
network_args       = ['conv_dim=24', 'conv_alpha=48.0', 'algo=locon', 'preset=full', 'train_norm=False', 'torch_compile=False', 'loraplus_lr_ratio=4', 'use_scalar=False']


[optimizer_arguments]
lr_scheduler       = "REX"
optimizer_type     = "AdamW8bit"
optimizer_args     = ["weight_decay=0.01"]
min_lr             = 0

[training_arguments]
max_train_epochs    = 15
protected_tags_file = "/home/bluvoll/Documentos/pipeline download/tags.txt"
loss_type          = "l2"
save_every_n_epochs = 1
save_every_n_steps = 20
save_last_n_epochs  = 5
train_batch_size   = 4
max_grad_norm      = 0
weighted_captions  = false
seed               = 65867997
max_token_length   = 225
lowram             = false
max_data_loader_n_workers = 4
persistent_data_loader_workers = true
save_precision     = "bf16"
mixed_precision    = "bf16"
full_bf16          = true
output_dir         = "/home/bluvoll/stable-diffusion-webui-reForge/models/Lora/"
output_name        = "NoobAI-RF-0.5TEST-AT"

[model_arguments]
pretrained_model_name_or_path = "/home/bluvoll/Descargas/NoobAI-RF-v0.5.safetensors"
v2                    = false
sdxl                  = true
gradient_checkpointing = true
gradient_accumulation_steps = 4 
sdpa                  = true
no_half_vae           = true

[saving_arguments]
save_model_as = "safetensors"


[dataset_arguments]
cache_latents              = true
cache_latents_to_disk      = true
lr_warmup_steps            = 30
